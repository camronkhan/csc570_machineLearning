---
title: "Boston Housing Prices"
output: html_notebook
---

Camron Khan<br>
April 2017

<br>

## Setup

```{r}
#install.packages("caret")
library(caret)
```

```{r}
rawData <- read.csv('./Boston.csv', stringsAsFactors = FALSE)
```

```{r}
set.seed(1)
```


<br>

## EDA

<br>

**Data Types**<br>
Most features are doubles; however, we have three features - *chas, rad, and tax* - that are integers. The feature *chas* is clearly categorical and has already been dummied; however, we must decide how to treat *rad* and *tax*. There's not enough information to make a clear judgment about *rad* - it's not clear if the "index of accessibility to radial highways" is referring to the number of access points availble or simply to an arbitrary scoring.  As a result, this variable must be dummied.  The feature *tax*, however, is referring to the property tax rate per \$10,000. Therefore, this appears to be better classified as a continuous value. It appears the index is included as a feature that we will need to remove from our dataframe. We will consider additional features to prune later in the analysis.

**Missing Values**<br>
Surprisingly, there are no missing values in this dataset; and therefore, there is no need for imputations.

**Variance**<br>
TODO

**Distributions**<br>
Below are the distributions for continuous variables:

* Normally Distributed: *rm*
* Left-Skewed: *age*, *ptratio*, *black*
* Right-Skewed: *crim*, *zn*, *nox*, *dis*, *lstat*, *medv*
* Unclassified: *indus*, *tax*

**Transformations**<br>
It may be worth performing a transformation on *tax* to get the tax rate as a percent (i.e., divide by \$10,000) for readability. All non-categorical features are postive with the exception of *zn*; therefore, we will need to devise a strategy for handling this feature if we want to use Box-Cox transformations to reduce skew.

**Correlated Predicors**
TODO

**Linear Dependencies**
TODO

```{r}
feature <- as.vector(colnames(rawData))

definition <- c("index", "per capita crime rate by town", "proportion of residential land zoned for lots over 25,000 sq.ft", "proportion of non-retail business acres per town", "Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)", "nitrogen oxides concentration (parts per 10 million)", "average number of rooms per dwelling", "proportion of owner-occupied units built prior to 1940", "weighted mean of distances to five Boston employment centers", "index of accessibility to radial highways", "full-value property-tax rate per $10,000", "pupil-teacher ratio by town", "1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town", "lower status of the population (percent)", "median value of owner-occupied homes in $1000s")

dataDefinitions <- data.frame(feature, definition, stringsAsFactors = FALSE)

print(dataDefinitions)
```

```{r}
print(str(rawData))
```

```{r}
print(summary(rawData))
```

```{r}
missingValues <- sapply(rawData, function(x) sum(is.na(x)))
print(missingValues)
```

```{r}
print(nearZeroVar(rawData, saveMetrics = TRUE))
```

```{r}
for (feature in names(subset(rawData, select = -c(X, chas, rad)))) {
  xlabel <- dataDefinitions$definition[dataDefinitions$feature == feature[1]]
  plot <- ggplot(rawData, aes(x = rawData[[feature]]), binwidth = 2) + 
            geom_histogram(aes(y = ..density..), fill = 'red', alpha = 0.5, bins = 40) + 
            geom_density(colour = 'blue') +
            xlab(xlabel) +
            ylab('density') +
            ggtitle(feature)
  print(plot)
}
```

<br>

## Preprocessing

<br>

**Steps**

1. Define a new dataframe for storing preprocessed data
2. Remove the index column *X*
3. Parse *rad* to dummies
4. Standardize values across features (i.e., center and scale)
5. Perform transformations (Box-Cox?, Yeo-Johnson?, IHS?)

```{r}
preprocessedData <- rawData[c(-1)]


```




